: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line291: Input Buffer begin
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line300: Input Buffer end!!
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line302: Bind Node to Compute Op Begin
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line336: Process Node Shape aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor Begin ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line361: Process Node Shape aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor End ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line363: Process Node Compute Op: aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor Begin ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line375: standard lowering ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line392: Process Node Compute Op: aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor End ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line336: Process Node Shape aten::mul.Scalar(Tensor self, Scalar other) -> Tensor Begin ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line361: Process Node Shape aten::mul.Scalar(Tensor self, Scalar other) -> Tensor End ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line363: Process Node Compute Op: aten::mul.Scalar(Tensor self, Scalar other) -> Tensor Begin ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line375: standard lowering ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line392: Process Node Compute Op: aten::mul.Scalar(Tensor self, Scalar other) -> Tensor End ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line397: Bind Node to Compute Op End
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line409: Original Functor: 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line410: {
  for (int64_t i = 0ll; i < 800ll; i++) {
    for (int64_t j = 0ll; j < 1333ll; j++) {
      for (int64_t k = 0ll; k < 3ll; k++) {
        aten_sub[i, j, k] = (InputBuf_0[i, j, k]) - float(1ll) * InputVar_0;
      }
    }
  }
  for (int64_t i_1 = 0ll; i_1 < 800ll; i_1++) {
    for (int64_t j_1 = 0ll; j_1 < 1333ll; j_1++) {
      for (int64_t k_1 = 0ll; k_1 < 3ll; k_1++) {
        aten_mul[i_1, j_1, k_1] = (aten_sub[i_1, j_1, k_1]) * InputVar_1;
      }
    }
  }
}
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line420: after compute inline: 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line421: {
  for (int64_t i_1 = 0ll; i_1 < 800ll; i_1++) {
    for (int64_t j_1 = 0ll; j_1 < 1333ll; j_1++) {
      for (int64_t k_1 = 0ll; k_1 < 3ll; k_1++) {
        aten_mul[i_1, j_1, k_1] = ((InputBuf_0[i_1, j_1, k_1]) - float(1ll) * InputVar_0) * InputVar_1;
      }
    }
  }
}
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line472: after loop binding: 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line473: for (int64_t new_axis_i = 0ll; new_axis_i < 1ll; new_axis_i++)  /* blockIdx.y */{
  for (int64_t i_1_flat_outer = 0ll; i_1_flat_outer < (((800ll * (1333ll * (3ll * 1ll)) - 0ll) + 512ll) - 1ll) / 512ll; i_1_flat_outer++)  /* blockIdx.x */{
    for (int64_t i_1_flat_inner = 0ll; i_1_flat_inner < 512ll; i_1_flat_inner++)  /* threadIdx.x */{
      if (i_1_flat_outer * 512ll + i_1_flat_inner<800ll * (1333ll * (3ll * 1ll)) ? 1 : 0) {
        aten_mul[(i_1_flat_outer * 512ll + i_1_flat_inner) / (1333ll * (3ll * 1ll)), ((i_1_flat_outer * 512ll + i_1_flat_inner) / (3ll * 1ll)) % 1333ll, ((i_1_flat_outer * 512ll + i_1_flat_inner) / 1ll) % 3ll] = ((InputBuf_0[(i_1_flat_outer * 512ll + i_1_flat_inner) / (1333ll * (3ll * 1ll)), ((i_1_flat_outer * 512ll + i_1_flat_inner) / (3ll * 1ll)) % 1333ll, ((i_1_flat_outer * 512ll + i_1_flat_inner) / 1ll) % 3ll]) - float(1ll) * InputVar_0) * InputVar_1;
      }
    }
  }
}
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line583: after parallization: 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line584: for (int64_t new_axis_i = 0ll; new_axis_i < 1ll; new_axis_i++)  /* blockIdx.y */{
  for (int64_t i_1_flat_outer = 0ll; i_1_flat_outer < (((800ll * (1333ll * (3ll * 1ll)) - 0ll) + 512ll) - 1ll) / 512ll; i_1_flat_outer++)  /* blockIdx.x */{
    for (int64_t i_1_flat_inner = 0ll; i_1_flat_inner < 512ll; i_1_flat_inner++)  /* threadIdx.x */{
      if (i_1_flat_outer * 512ll + i_1_flat_inner<800ll * (1333ll * (3ll * 1ll)) ? 1 : 0) {
        aten_mul_0[(i_1_flat_outer * 512ll + i_1_flat_inner) / (1333ll * (3ll * 1ll)), ((i_1_flat_outer * 512ll + i_1_flat_inner) / (3ll * 1ll)) % 1333ll, ((i_1_flat_outer * 512ll + i_1_flat_inner) / 1ll) % 3ll] = ((InputBuf_0_0[(i_1_flat_outer * 512ll + i_1_flat_inner) / (1333ll * (3ll * 1ll)), ((i_1_flat_outer * 512ll + i_1_flat_inner) / (3ll * 1ll)) % 1333ll, ((i_1_flat_outer * 512ll + i_1_flat_inner) / 1ll) % 3ll]) - float(1ll) * InputVar_0_0) * InputVar_1_0;
      }
    }
  }
}
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line592: after pre codegen: 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line593: for (int64_t new_axis_i = 0ll; new_axis_i < 1ll; new_axis_i++)  /* blockIdx.y */{
  for (int64_t i_1_flat_outer = 0ll; i_1_flat_outer < (((800ll * (1333ll * (3ll * 1ll)) - 0ll) + 512ll) - 1ll) / 512ll; i_1_flat_outer++)  /* blockIdx.x */{
    for (int64_t i_1_flat_inner = 0ll; i_1_flat_inner < 512ll; i_1_flat_inner++)  /* threadIdx.x */{
      if (i_1_flat_outer * 512ll + i_1_flat_inner<800ll * (1333ll * (3ll * 1ll)) ? 1 : 0) {
        aten_mul_0[((0ll + ((i_1_flat_outer * 512ll + i_1_flat_inner) / (1333ll * (3ll * 1ll))) * ((1ll * 3ll) * 1333ll)) + (((i_1_flat_outer * 512ll + i_1_flat_inner) / (3ll * 1ll)) % 1333ll) * (1ll * 3ll)) + (((i_1_flat_outer * 512ll + i_1_flat_inner) / 1ll) % 3ll) * 1ll] = ((InputBuf_0_0[((0ll + ((i_1_flat_outer * 512ll + i_1_flat_inner) / (1333ll * (3ll * 1ll))) * ((1ll * 3ll) * 1333ll)) + (((i_1_flat_outer * 512ll + i_1_flat_inner) / (3ll * 1ll)) % 1333ll) * (1ll * 3ll)) + (((i_1_flat_outer * 512ll + i_1_flat_inner) / 1ll) % 3ll) * 1ll]) - float(1ll) * InputVar_0_0) * InputVar_1_0;
      }
    }
  }
}
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line659: after codegen: 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: compile: Line661: 
#define NAN __int_as_float(0x7fffffff)
#define POS_INFINITY __int_as_float(0x7f800000)
#define NEG_INFINITY __int_as_float(0xff800000)


template<typename T>
__device__ T maximum(T a, T b) {
  return isnan(a) ? a : (a > b ? a : b);
}

template<typename T>
__device__ T minimum(T a, T b) {
  return isnan(a) ? a : (a < b ? a : b);
}

extern "C" __global__
void functor_0_0(float* InputBuf_0_0, float InputVar_0_0, float InputVar_1_0, float* aten_mul_0) {
{
if ((long long)(threadIdx.x) + 512ll * (long long)(blockIdx.x)<3199200ll ? 1 : 0) {
    float v = __ldg(InputBuf_0_0 + (long long)(threadIdx.x) + 512ll * (long long)(blockIdx.x));
    aten_mul_0[(long long)(threadIdx.x) + 512ll * (long long)(blockIdx.x)] = (v - InputVar_0_0) * InputVar_1_0;
  }}
}
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: runKernel: Line856: run kernel begin: 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: runKernel: Line860: Preparing call args ... ... 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: prepareRunArgs: Line681: solve input begin
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: prepareRunArgs: Line685: preparing input and shape call args ... ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: prepareRunArgs: Line820: preparing input and shape call args DONE!!!
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: prepareRunArgs: Line851: solve input done
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: runKernel: Line863: Preparing call args DONE!!! 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: runKernel: Line864: run kernel call begin ... 
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: runKernel: Line870: run kernel call end ...
: [1;91m[Info][m /home/jimyma/project/TensorSSA/FuncTs/fait/fuser/graph_builder.cpp: runKernel: Line881: run kernel end ...
graph(%self : __torch__.___torch_mangle_1.Normalize,
      %src.1 : Float(800, 1333, 3, device=cuda),
      %mean.1 : float,
      %scale.1 : float):
  %8 : int = prim::Constant[value=0]() # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:12:18
  %7 : int = prim::Constant[value=2]() # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:12:33
  %6 : NoneType = prim::Constant()
  %5 : int = prim::Constant[value=1]() # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:12:23
  %4 : bool = prim::Constant[value=0]()
  %dup.1 : Float(800, 1333, 3, device=cuda) = aten::clone(%src.1, %6) # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:11:14
  %12 : Float(800, 1333, device=cuda) = aten::select(%src.1, %7, %7) # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:12:23
  %26 : Float(800, 1333, 3, device=cuda) = immut::slice(%dup.1, %8, %6, %6, %5)
  %27 : Float(800, 1333, 3, device=cuda) = immut::slice(%26, %5, %6, %6, %5)
  %28 : Float(800, 1333, device=cuda) = immut::select(%27, %7, %8)
  %34 : Float(800, 1333, device=cuda) = immut::assign(%28, %12, %4)
  %35 : Float(800, 1333, 3, device=cuda) = immut::select_rev(%27, %34, %7, %8)
  %36 : Float(800, 1333, 3, device=cuda) = immut::slice_rev(%26, %35, %5, %6, %6, %5)
  %37 : Float(800, 1333, 3, device=cuda) = immut::slice_rev(%dup.1, %36, %8, %6, %6, %5)
  %19 : Float(800, 1333, device=cuda) = aten::select(%src.1, %7, %8) # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:13:23
  %30 : Float(800, 1333, 3, device=cuda) = immut::slice(%37, %8, %6, %6, %5)
  %31 : Float(800, 1333, 3, device=cuda) = immut::slice(%30, %5, %6, %6, %5)
  %32 : Float(800, 1333, device=cuda) = immut::select(%31, %7, %7)
  %41 : Float(800, 1333, device=cuda) = immut::assign(%32, %19, %4)
  %42 : Float(800, 1333, 3, device=cuda) = immut::select_rev(%31, %41, %7, %7)
  %43 : Float(800, 1333, 3, device=cuda) = immut::slice_rev(%30, %42, %5, %6, %6, %5)
  %44 : Float(800, 1333, 3, device=cuda) = immut::slice_rev(%37, %43, %8, %6, %6, %5)
  %58 : Float(800, 1333, 3, device=cuda) = tssa::ParallelFunctor_0[input_refine_types=[Float(800, 1333, 3, device=cuda), float, float], parallel_degree=1, is_parallel_map=0, is_parallel_args=[1, 1, 1]](%44, %mean.1, %scale.1)
  return (%58)
with tssa::ParallelFunctor_0 = graph(%0 : NoneType,
      %1 : Float(800, 1333, 3, device=cuda),
      %2 : float,
      %3 : float):
  %5 : int = prim::Constant[value=1]() # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:12:23
  %4 : Float(800, 1333, 3, device=cuda) = aten::sub(%1, %2, %5) # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:14:16
  %6 : Float(800, 1333, 3, device=cuda) = aten::mul(%4, %3) # /home/jimyma/project/TensorSSA/FuncTs/benchmark/simpleops/normalize/normalize.py:14:16
  return (%6)

True
True
